import streamlit as st
import pandas as pd
import matplotlib.pyplot as plt
import numpy as np
import seaborn as sns
from sklearn.model_selection import train_test_split, cross_val_score
from sklearn.preprocessing import StandardScaler
from sklearn.linear_model import LinearRegression
from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score
from streamlit_extras.metric_cards import style_metric_cards
from datetime import datetime

st.set_option('deprecation.showPyplotGlobalUse', False)
st.set_page_config(page_title="Ph√¢n T√≠ch H·ªçc T·∫≠p NEU", page_icon="üìà", layout="wide")

with open('style.css') as f:
    st.markdown(f"<style>{f.read()}</style>", unsafe_allow_html = True)

current_datetime = datetime.now()
formatted_date = current_datetime.strftime('%Y-%m-%d')
formatted_day = current_datetime.strftime('%A')

st.header(" MACHINE LEARNING | MYSQL  ")
st.markdown(
    """
    <link href="https://cdn.jsdelivr.net/npm/bootstrap@5.3.2/dist/css/bootstrap.min.css" rel="stylesheet">
    <hr>
    <div class="card mb-3">
        <div class="card">
            <div class="card-body">
                <h3 class="card-title"style="color:#007710;"><strong> PH√ÇN T√çCH H·ªíI QUY ƒêA BI·∫æN </strong></h3>
                <p class="card-text">C√≥ ba bi·∫øn, ƒêi·ªÉm TBC, ƒêi·ªÉm r√®n luy·ªán v√† S·ªë t√≠n ch·ªâ. M·ª•c ƒë√≠ch l√† ƒë·ªÉ ki·ªÉm tra xem m·ªëi quan h·ªá tuy·∫øn t√≠nh gi·ªØa c√°c bi·∫øn n√†y xa ƒë·∫øn m·ª©c n√†o, trong ƒë√≥ ƒêi·ªÉm r√®n luy·ªán v√† S·ªë t√≠n ch·ªâ l√† c√°c ƒë·∫∑c ƒëi·ªÉm X v√† ƒêi·ªÉm TBC l√† ƒë·∫∑c ƒëi·ªÉm Y. ƒê√¢y l√† m·ªôt v·∫•n ƒë·ªÅ ph√¢n lo·∫°i s·ª≠ d·ª•ng ph√¢n t√≠ch h·ªìi quy b·ªôi x√°c su·∫•t cho d·ªØ li·ªáu t·ªìn t·∫°i trong mysql. ƒêo l∆∞·ªùng tr·ª±c quan v·ªÅ c√°c bi·∫øn th·ªÉ v√† ƒë∆∞·ªùng ph√π h·ª£p nh·∫•t</p>
                <p class="card-text"><small class="text-body-secondary"> </small></p>
            </div>
        </div>
    </div>
    <style>
        [data-testid=stSidebar] {
            color: white;
            text-size:24px;
        }
    </style>
    """,
    unsafe_allow_html=True
)

#1. read data from mysql
#2. result = view_all_data()
#3. df = pd.DataFrame(result,columns=["id","year","month","interest_rate","unemployment_rate","index_price"])

df=pd.read_excel("./datasets/Danh_sach_du_kien_HBKKHT_HK II-2022-2023.xlsx")

with st.sidebar:
    st.markdown(f"<h4 class='text-success'>{formatted_day}: {formatted_date}</h4>Analytics Dashboard V: 01/2023<hr>", unsafe_allow_html=True)

khoa= st.sidebar.multiselect(
    "CH·ªåN KH√ìA:",
    options=df["Khoa"].unique(),
    default=df["Khoa"].unique()
)

suatHB = st.sidebar.multiselect(
    "CH·ªåN Su·∫•t HB H·ªåC K·ª≤ II:",
    options=df["SuatHB"].unique(),
    default=df["SuatHB"].unique(),
)

df_selection = df.query(
    "Khoa == @khoa & SuatHB == @suatHB"
)

with st.sidebar:
    df_download = df_selection.to_csv(index=False).encode('utf-8')
    st.download_button(
        label="Download DataFrame from Mysql",
        data=df_download,
        key="download_dataframe.csv",
        file_name="my_dataframe.csv"
)
    
df_selection.drop(columns=["Stt","MSV","Ho", "Ten", "Lop", "ChuyenNganh", "Khoa/Vien", "LoaiHB"],axis=1,inplace=True)

#theme_plotly = None 

with st.expander("EXPLORATORY ANALYSIS (Ph√¢n t√≠ch kh√°m ph√° d·ªØ li·ªáu)"):
    st.write("Ki·ªÉm tra m·ªëi t∆∞∆°ng quan gi·ªØa c√°c bi·∫øn (ƒë·∫∑c ƒëi·ªÉm) ƒë·ªôc l·∫≠p v√† bi·∫øn ph·ª• thu·ªôc tr∆∞·ªõc khi th·ª±c s·ª± x√¢y d·ª±ng v√† hu·∫•n luy·ªán m√¥ h√¨nh h·ªìi quy. ƒê√¢y l√† m·ªôt b∆∞·ªõc quan tr·ªçng trong giai ƒëo·∫°n kh√°m ph√° v√† ph√¢n t√≠ch d·ªØ li·ªáu ban ƒë·∫ßu ƒë·ªÉ hi·ªÉu m·ªëi quan h·ªá gi·ªØa c√°c bi·∫øn.")
    col_a,col_b=st.columns(2)
    with col_a:
        st.subheader("S·ªë t√≠n ch·ªâ t√≠ch l≈©y vs ƒêi·ªÉm TBC HKII")
        plt.figure(figsize=(4, 4))
        sns.regplot(x=df_selection['SoTCTichLuyHocKyII'], y=df_selection['DiemTBCHT_HKII'],color="#007710")
        plt.xlabel('S·ªë t√≠n ch·ªâ t√≠ch l≈©y')
        plt.ylabel('ƒêi·ªÉm TBC HKII')
        plt.title('ƒêi·ªÉm TBC HKII vs S·ªë t√≠n ch·ªâ t√≠ch l≈©y: Regression Plot')
        st.pyplot()

with col_b:
    plt.figure(figsize=(4, 4))
    st.subheader("ƒêi·ªÉm r√®n luy·ªán HKII vs ƒêi·ªÉm TBC HKII")
    sns.regplot(x=df_selection['DiemRL_HKII'], y=df_selection['DiemTBCHT_HKII'],color="#007710")
    plt.xlabel('ƒêi·ªÉm r√®n luy·ªán HKII')
    plt.ylabel('ƒêi·ªÉm TBC HKII')
    plt.title('ƒêi·ªÉm r√®n luy·ªán HKII vs ƒêi·ªÉm TBC HKII Regression Plot')
    st.pyplot()

    fig, ax = plt.subplots()
    st.subheader("C√°c bi·∫øn ngo·∫°i l·ªá",)
    sns.boxplot(data=df, orient='h',color="#FF4B4B")
    plt.show()
    st.pyplot()

with st.expander("Ph√¢n t√≠ch theo t·∫ßn s·ªë: HISTOGRAM"):
    df_selection.hist(figsize=(16,8),color='#007710', zorder=2, rwidth=0.9,legend = ['unemployment_rate']);
    st.pyplot()

with st.expander("Ph√¢n t√≠ch kh√°m ph√° d·ªØ li·ªáu"):
    st.subheader("T∆∞∆°ng quan gi·ªØa c√°c bi·∫øn",)
    #https://seaborn.pydata.org/generated/seaborn.pairplot.html
    pairplot = sns.pairplot(df_selection,plot_kws=dict(marker="+", linewidth=1), diag_kws=dict(fill=True))
    st.pyplot(pairplot.figure)

with st.expander("C√ÅC GI√Å TR·ªä NULL, XU H∆Ø·ªöNG & PH√ÇN T√çCH BI·∫æN ƒê·ªîI"):
    a1,a2=st.columns(2)
    a1.write("s·ªë l∆∞·ª£ng c√°c gi√° tr·ªã b·ªã thi·∫øu c·ªßa m·ªói c·ªôt (NaN or None)")
    a1.dataframe(df_selection.isnull().sum(),use_container_width=True)
    a2.write("c√°i nh√¨n s√¢u s·∫Øc v·ªÅ xu h∆∞·ªõng trung t√¢m, s·ª± ph√¢n t√°n v√† ph√¢n ph·ªëi d·ªØ li·ªáu.")
    a2.dataframe(df_selection.describe().T,use_container_width=True)

# train and test split
with st.expander("S·ª± t∆∞∆°ng quan m·∫∑c ƒë·ªãnh"):
    st.dataframe(df_selection.corr())
    st.subheader("S·ª± t∆∞∆°ng quan",)
    st.write("h·ªá s·ªë t∆∞∆°ng quan ƒëi·ªÉm TBC v√† s·ªë l∆∞·ª£ng t√≠n ch·ªâ")
    plt.scatter(df_selection['DiemTBCHT_HKII'], df_selection['SoTCTichLuyHocKyII'])
    plt.ylabel("ƒêi·ªÉm TBC")
    plt.xlabel("S·ªë l∆∞·ª£ng t√≠n ch·ªâ")
    st.pyplot()

try:
    # independent and dependent features
    X=df_selection.iloc[:,:-1] #left a last column
    y=df_selection.iloc[:,-1] #take a last column

    # train test split
    X_train,X_test,y_train,y_test=train_test_split(X,y,test_size=0.25,random_state=42)

    with st.expander(" S·ª∞ PH√ÇN PH·ªêI ƒê·ªíNG ƒê·ªÄU"):
        st.subheader("ƒêi·ªÉm chu·∫©n (Z-Scores)",)
        st.write("chuy·ªÉn ƒë·ªïi d·ªØ li·ªáu sao cho n√≥ c√≥ gi√° tr·ªã trung b√¨nh (trung b√¨nh) b·∫±ng 0 v√† ƒë·ªô l·ªách chu·∫©n l√† 1. Qu√° tr√¨nh n√†y c√≤n ƒë∆∞·ª£c g·ªçi l√† [chia t·ª∑ l·ªá] ho·∫∑c [chu·∫©n h√≥a.]")
        scaler=StandardScaler()
        X_train=scaler.fit_transform(X_train)
        X_test=scaler.fit_transform(X_test)
        st.dataframe(X_train)

    regression=LinearRegression()
    regression.fit(X_train,y_train)

    #cross validation
    validation_score=cross_val_score(regression,X_train,y_train,scoring='neg_mean_squared_error',cv=3)

    col1, col3,col4,col5 = st.columns(4)
    col1.metric(label="X√ÅC ƒê·ªäNH ƒêI·ªÇM TRUNG B√åNH", value=np.mean(validation_score), delta=f"{ np.mean(validation_score):,.0f}")

    #prediction
    y_pred=regression.predict(X_test)

  # performance metrics
    meansquareerror=mean_squared_error(y_test,y_pred)
    meanabsluteerror=mean_absolute_error(y_test,y_pred)
    rootmeansquareerror=np.sqrt(meansquareerror)

    col3.metric(label=" MEAN SQUARED ERROR (SAI S·ªê B√åNH PH∆Ø∆†NG TRUNG B√åNH)", value=np.mean(meansquareerror), delta=f"{ np.mean(meansquareerror):,.0f}")
    col4.metric(label=" MEAN ABSOLUTE ERROR (ƒëo ƒë·ªô l·ªõn trung b√¨nh c·ªßa c√°c l·ªói)", value=np.mean(meanabsluteerror), delta=f"{ np.mean(meanabsluteerror):,.0f}")
    col5.metric(label=" ROOT MEAN SQUARED ERROR (cƒÉn b·∫≠c hai c·ªßa m·ª©c trung b√¨nh c·ªßa c√°c sai s·ªë b√¨nh ph∆∞∆°ng)", value=np.mean(rootmeansquareerror), delta=f"{ np.mean(rootmeansquareerror):,.0f}")

    with st.expander(" COEFFICIENT OF DETERMINATION (H·ªá s·ªë x√°c ƒë·ªãnh) | R2"):
        score=r2_score(y_test,y_pred)
        st.metric(label="üî∑ r", value=float(score), delta=f"{ score:,.0f}")

    with st.expander(" ADJUSTED CORRERATION COEFFICIENT (H·ªá s·ªë ƒëi·ªÅu ch·ªânh t∆∞∆°ng quan) | R"):
        st.metric(label="üî∑ Adjusted R", value=float((1-(1-score)*(len(y_test)-1)/(len(y_test)-X_test.shape[1]-1))), delta=f"{ ((1-(1-score)*(len(y_test)-1)/(len(y_test)-X_test.shape[1]-1))):,.0f}")
    
    with st.expander(" CORRERATION COEFFICIENT (H·ªá s·ªë t∆∞∆°ng quan) | r"):
        st.write(regression.coef_)
 
    #https://seaborn.pydata.org/generated/seaborn.regplot.html
    c1,c2,c3=st.columns(3)
    with c1:
        with st.expander(" LINE OF BEST FIT (H·ªìi quy tuy·∫øn t√≠nh)"):
            st.write("ƒë∆∞·ªùng h·ªìi quy th·ªÉ hi·ªán r√µ nh·∫•t m·ªëi quan h·ªá gi·ªØa (c√°c) bi·∫øn ƒë·ªôc l·∫≠p v√† bi·∫øn ph·ª• thu·ªôc trong m√¥ h√¨nh h·ªìi quy tuy·∫øn t√≠nh. ƒê∆∞·ªùng n√†y ƒë∆∞·ª£c x√°c ƒë·ªãnh th√¥ng qua m·ªôt quy tr√¨nh to√°n h·ªçc nh·∫±m gi·∫£m thi·ªÉu sai s·ªë gi·ªØa c√°c ƒëi·ªÉm d·ªØ li·ªáu ƒë∆∞·ª£c quan s√°t v√† c√°c gi√° tr·ªã d·ª± ƒëo√°n do m√¥ h√¨nh t·∫°o ra.")
            plt.figure(figsize=(8, 6))
            sns.regplot(x=y_test, y=y_pred,color="#FF4B4B",line_kws=dict(color="#007710"))
            plt.xlabel('ƒêi·ªÉm TBC')
            plt.ylabel('S·ªë l∆∞·ª£ng t√≠n ch·ªâ')
            plt.title('ƒêi·ªÉm TBC vs S·ªë l∆∞·ª£ng t√≠n ch·ªâ Regression Plot')
            st.pyplot()

    with c2:
        with st.expander(" RESIDUAL (C√°c ph·∫ßn d∆∞)"):
            st.write("ph·∫ßn d∆∞: ƒë·ªÅ c·∫≠p ƒë·∫øn s·ª± kh√°c bi·ªát gi·ªØa c√°c gi√° tr·ªã quan s√°t th·ª±c t·∫ø (bi·∫øn ph·ª• thu·ªôc, th∆∞·ªùng ƒë∆∞·ª£c k√Ω hi·ªáu l√† y) v√† c√°c gi√° tr·ªã d·ª± ƒëo√°n ƒë∆∞·ª£c ƒë∆∞a ra b·ªüi m√¥ h√¨nh h·ªìi quy (th∆∞·ªùng ƒë∆∞·ª£c k√Ω hi·ªáu l√† y_pred). C√°c ph·∫ßn d∆∞ n√†y th·ªÉ hi·ªán m·ª©c ƒë·ªô d·ª± ƒëo√°n c·ªßa m√¥ h√¨nh sai l·ªách so v·ªõi c√°c ƒëi·ªÉm d·ªØ li·ªáu th·ª±c t·∫ø")
            residuals=y_test-y_pred
            st.dataframe(residuals)

    with c3:
        with st.expander(" MODEL PERFORMANCE | NORMAL DISTRIBUTION CURVE (HI·ªÜU SU·∫§T M√î H√åNH | ƒê∆Ø·ªúNG CUNG PH√ÇN PH·ªêI B√åNH TH∆Ø·ªúNG) "):
            st.write("s·ª± ph√¢n b·ªë c·ªßa m·ªôt bi·∫øn ng·∫´u nhi√™n li√™n t·ª•c trong ƒë√≥ d·ªØ li·ªáu c√≥ xu h∆∞·ªõng ƒë∆∞·ª£c ph√¢n b·ªë ƒë·ªëi x·ª©ng xung quanh m·ªôt gi√° tr·ªã trung b√¨nh (trung b√¨nh). ƒê√¢y l√† m·ªôt kh√°i ni·ªám c∆° b·∫£n trong th·ªëng k√™ v√† l√Ω thuy·∫øt x√°c su·∫•t.")
            sns.displot(residuals,kind='kde',legend=True,color="#007710")
            st.pyplot()

    with st.expander(" Ordinary Least Squares Method (Ph∆∞∆°ng ph√°p b√¨nh ph∆∞∆°ng t·ªëi thi·ªÉu)"): 
        import statsmodels.api as sm
        model=sm.OLS(y_train,X_train).fit()
        st.write(model.summary())

    style_metric_cards(background_color="#FFFFFF",border_left_color="#686664",border_color="#000000",box_shadow=True)

except:
    st.error("ERROR: L∆Ø·ª¢NG D·ªÆ LI·ªÜU KH√îNG ƒê·ª¶ ƒê·ªÇ M√î H√åNH HO·∫†T ƒê·ªòNG")